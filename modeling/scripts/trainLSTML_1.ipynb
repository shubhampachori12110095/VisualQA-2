{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Merge, Dropout, Reshape\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from keras.callbacks import ModelCheckpoint, RemoteMonitor\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from spacy.en import English\n",
    "\n",
    "from utils import grouper, selectFrequentAnswers\n",
    "from features import get_images_matrix, get_answers_matrix, get_questions_tensor_timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-num_hidden_units_mlp', type=int, default=1024)\n",
    "parser.add_argument('-num_hidden_units_lstm', type=int, default=512)\n",
    "parser.add_argument('-num_hidden_layers_mlp', type=int, default=1)\n",
    "parser.add_argument('-num_hidden_layers_lstm', type=int, default=1)\n",
    "parser.add_argument('-dropout', type=float, default=0.5)\n",
    "parser.add_argument('-activation_mlp', type=str, default='tanh')\n",
    "parser.add_argument('-num_epochs', type=int, default=1)\n",
    "parser.add_argument('-model_save_interval', type=int, default=5)\n",
    "parser.add_argument('-batch_size', type=int, default=128)\n",
    "parser.add_argument('-f', type=str, default='')\n",
    "#TODO Feature parser.add_argument('-resume_training', type=str)\n",
    "#TODO Feature parser.add_argument('-language_only', type=bool, default= False)\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vec_dim= 300\n",
    "img_dim = 4096\n",
    "max_len = 30\n",
    "nb_classes = 1000\n",
    "\n",
    "#get the data\n",
    "questions_train = open('../data/preprocessed/questions_train2014.txt', 'r').read().decode('utf8').splitlines()\n",
    "questions_lengths_train = open('../data/preprocessed/questions_lengths_train2014.txt', 'r').read().decode('utf8').splitlines()\n",
    "answers_train = open('../data/preprocessed/answers_train2014_modal.txt', 'r').read().decode('utf8').splitlines()\n",
    "images_train = open('../data/preprocessed/images_train2014.txt', 'r').read().decode('utf8').splitlines()\n",
    "vgg_model_path = '../features/coco/vgg_feats.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_answers = nb_classes\n",
    "questions_train, answers_train, images_train = \\\n",
    "    selectFrequentAnswers(questions_train,answers_train,images_train, max_answers)\n",
    "questions_lengths_train, questions_train, answers_train, images_train = \\\n",
    "    (list(t) for t in zip(*sorted(zip(questions_lengths_train, questions_train, answers_train, images_train))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print questions_lengths_train[:1]\n",
    "print questions_train[:1]\n",
    "print answers_train[:1]\n",
    "print images_train[:1]\n",
    "\n",
    "print len(questions_lengths_train)\n",
    "print len(questions_train)\n",
    "print len(answers_train)\n",
    "print len(images_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#encode the remaining answers\n",
    "labelencoder = preprocessing.LabelEncoder()\n",
    "labelencoder.fit(answers_train)\n",
    "nb_classes = len(list(labelencoder.classes_))\n",
    "joblib.dump(labelencoder,'../models/labelencoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_model = Sequential()\n",
    "image_model.add(Reshape((img_dim,), input_shape = (img_dim,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "language_model = Sequential()\n",
    "\n",
    "if args.num_hidden_layers_lstm == 1:\n",
    "    language_model.add(LSTM(output_dim = args.num_hidden_units_lstm,\n",
    "                            return_sequences=False,\n",
    "                            input_shape=(max_len, word_vec_dim)))\n",
    "else:\n",
    "    language_model.add(LSTM(output_dim = args.num_hidden_units_lstm,\n",
    "                            return_sequences=True,\n",
    "                            input_shape=(max_len, word_vec_dim)))\n",
    "    for i in xrange(args.num_hidden_layers_lstm-2):\n",
    "        language_model.add(LSTM(output_dim = args.num_hidden_units_lstm, return_sequences=True))\n",
    "    language_model.add(LSTM(output_dim = args.num_hidden_units_lstm, return_sequences=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Merge([language_model, image_model], mode='concat', concat_axis=1))\n",
    "for i in xrange(args.num_hidden_layers_mlp):\n",
    "    model.add(Dense(args.num_hidden_units_mlp, init='uniform'))\n",
    "    model.add(Activation(args.activation_mlp))\n",
    "    model.add(Dropout(args.dropout))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(image_model.summary())\n",
    "print ':'*100\n",
    "print(language_model.summary())\n",
    "print ':'*100\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "json_string = model.to_json()\n",
    "model_file_name = '../models/lstm_1_num_hidden_units_lstm_' + str(args.num_hidden_units_lstm) + \\\n",
    "                    '_num_hidden_units_mlp_' + str(args.num_hidden_units_mlp) + '_num_hidden_layers_mlp_' + \\\n",
    "                    str(args.num_hidden_layers_mlp) + '_num_hidden_layers_lstm_' + str(args.num_hidden_layers_lstm)\n",
    "open(model_file_name + '.json', 'w').write(json_string)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "print 'Compilation done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_struct = scipy.io.loadmat(vgg_model_path)\n",
    "VGGfeatures = features_struct['feats']\n",
    "print 'loaded vgg features'\n",
    "image_ids = open('../features/coco_vgg_IDMap.txt').read().splitlines()\n",
    "img_map = {}\n",
    "for ids in image_ids:\n",
    "    id_split = ids.split()\n",
    "    img_map[id_split[0]] = int(id_split[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nlp = English()\n",
    "print 'loaded word2vec features...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## training\n",
    "print 'Training started for ', args.num_epochs, 'epochs ...'\n",
    "for k in xrange(args.num_epochs):\n",
    "\n",
    "    progbar = generic_utils.Progbar(len(questions_train))\n",
    "\n",
    "    for qu_batch,an_batch,im_batch in zip(grouper(questions_train, args.batch_size, fillvalue=questions_train[-1]), \n",
    "                                            grouper(answers_train, args.batch_size, fillvalue=answers_train[-1]), \n",
    "                                            grouper(images_train, args.batch_size, fillvalue=images_train[-1])):\n",
    "        X_q_batch = get_questions_tensor_timeseries(qu_batch, nlp, max_len)\n",
    "        X_i_batch = get_images_matrix(im_batch, img_map, VGGfeatures)\n",
    "        Y_batch = get_answers_matrix(an_batch, labelencoder)\n",
    "        loss = model.train_on_batch([X_q_batch, X_i_batch], Y_batch)\n",
    "        progbar.add(args.batch_size, values=[(\"train loss\", loss)])\n",
    "\n",
    "\n",
    "    if k%args.model_save_interval == 0:\n",
    "        model.save_weights(model_file_name + '_epoch_{:03d}.hdf5'.format(k))\n",
    "\n",
    "model.save_weights(model_file_name + '_epoch_{:03d}.hdf5'.format(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print timesteps, nlp(qu_batch[0])\n",
    "print len(im_batch), im_batch[3]\n",
    "print len(an_batch), an_batch[0]\n",
    "print len(qu_batch), qu_batch[0]\n",
    "print len(X_q_batch)\n",
    "print len(X_i_batch)\n",
    "print len(Y_batch)\n",
    "print X_q_batch.shape\n",
    "print X_i_batch.shape\n",
    "print Y_batch.shape"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
